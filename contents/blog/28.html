<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="google-site-verification" content="" />
    <title>配置 VSCode 的免费 AI 编程助手：Ollama 、Groq和 Continue 扩展 - GeoQiao's Blog</title>
    <meta name="description" content="探索学习 Python 的数据分析师，包括 Python教程、学习路径、常用工具、 VSCode 配置及数据分析等领域的相关知识。">
    <link rel="stylesheet" href="https://geoqiao.github.io/templates/default_theme/static/css/style.css">
    <link rel="stylesheet" href="https://geoqiao.github.io/templates/default_theme/static/css/prism.css">
    <link rel="alternate" type="application/atom+xml" title="RSS" href="/contents/atom.xml">
    <link rel="icon" type="image/png"
        href="https://geoqiao.github.io/templates/default_theme/static/images/favicon.png">
</head>

<body>
    <header>
        <nav class="container">
            <a href="/" class="logo">GeoQiao's Blog</a>
            <button class="menu-toggle" aria-label="Toggle menu">
                <span></span>
                <span></span>
                <span></span>
            </button>
            <ul class="nav-links">
                <li><a href="/contents/">Blog</a></li>
                <li><a href="/contents/tags">Tag</a></li>
                <li><a href="/">About</a></li>
                <li><a href="/contents/atom.xml">RSS</a></li>
            </ul>
        </nav>
    </header>

    <main class="container">
        
<article class="post full-post">
    <h1 class="post-title">配置 VSCode 的免费 AI 编程助手：Ollama 、Groq和 Continue 扩展</h1>
    <div class="post-meta">
        发布于 2024-11-16
        
        | 标签:
        
        <a href="/tag/VSCode.html" class="tag">VSCode</a>
        
        <a href="/tag/copilot.html" class="tag">copilot</a>
        
        
    </div>
    <div class="post-content">
        <p>这篇 issue 展示通过配置 Ollama 和 Continue 扩展，为 VSCode 配置免费、本地的 AI 编程助手。</p>
<p>我在体验了 cursor 之后，立即寻找类似 cursor 的免费解决方案。最终发现使用 Continue 配置自定义的 API 是相对比较简单，且实用的方法。</p>
<blockquote>
<p><strong>Ollama</strong>: 是一个开源框架，专为在本地机器上便捷部署和运行大型语言模型（LLM）而设计。使用 ollama 可以在自己的本地电脑上运行开源大模型。</p>
<p><strong>Groq</strong>: 是一家专注于人工智能芯片研发的公司，目前提供的 API key 是完全免费的</p>
<p><strong>Continue</strong>: 是一个 VSCode 的 AI 助手扩展，提供付费版本、免费但需自定义 API 两种方式配置自己要使用的 AI 模型。</p>
</blockquote>
<h2>方案一：使用 Ollama</h2>
<h3>安装 Ollama</h3>
<p>Ollama 现在支持 Windows、Linux、macOS，是一个真正意义上的跨平台本地大模型解决方案，安装使用起来也比较简单。</p>
<pre><code class="language-markdown">进入 Ollama [官网](https://ollama.com/)，点击 Download，即可完成下载安装
</code></pre>
<h3>安装本地大模型</h3>
<p>因为我的电脑内存为 16G，安装参数比较大的模型运行会比较慢，所以我这边推荐<code>qwen2.5-coder:7b</code> 或者 <code>codeqwen 7b</code>。</p>
<p>这两个模型的编程能力都比较强，并且参数只有 7b，运行在我的本地机器上还算比较流畅。</p>
<p>安装也比较简单，打开终端，每个模型大概不到 5G，运行命令后等待下载成功即可：</p>
<pre><code class="language-bash"># 如果内存吃紧可以仅安装一个
ollama run codeqwen   # 安装 codeqwen
ollama run qwen2.5-coder:7b # 安装 qwen2.5-coder:7b
</code></pre>
<h3>安装 Continue</h3>
<p>在 VSCode 的扩展商店搜索 Continue 并安装。Continue 对新用户提供可免费试用，可以使用 Claude 和 ChatGPT 的最新模型。</p>
<h3>修改 Continue 的配置文件</h3>
<p>将这段 JSON 配置粘贴入 Continue 的 config.json 中，Continue 便会自动检测本地已经安装的大模型</p>
<pre><code class="language-json">{
&quot;title&quot;: &quot;Autodetect&quot;,
&quot;provider&quot;: &quot;ollama&quot;,
&quot;model&quot;: &quot;AUTODETECT&quot;,
&quot;systemMessage&quot;: &quot;You are an expert software developer. You give helpful and concise responses.You will think in English and reply in Chinese&quot;
},
</code></pre>
<h2>方案二：使用 Groq-API</h2>
<h3>生成自己的 API key</h3>
<p>打开官方的<a href="https://console.groq.com/keys">API Keys 生成页面</a>，使用 GitHub 或者 Google 登录，然后直接点击<code>Create API Key</code>即可</p>
<h3>配置 Continue</h3>
<p>将这段 JSON 配置粘贴入 Continue 的 config.json 中，将 apikey 替换为自己的，Continue 便会自动检测 API 可以调用的大模型</p>
<pre><code class="language-json">{
&quot;model&quot;: &quot;AUTODETECT&quot;,
&quot;title&quot;: &quot;Autodetect&quot;,
&quot;apiKey&quot;: &quot;&lt;your API key&gt;&quot;,
&quot;provider&quot;: &quot;groq&quot;,
&quot;systemMessage&quot;: &quot;You are an expert software developer. You give helpful and concise responses.You will think in English and reply in Chinese &quot;
}
</code></pre>
<p>值得一提的是，groq 的生成速度非常快，而且支持调用 70b，甚至更大参数的模型，使用体验要比本地的 ollama 好上不少。</p>
<h2>结论</h2>
<p>现在给自己配置一个免费的编程助手真的不要太简单，虽然能力上还不如 Claude，但是日常使用已经非常够用了</p>
<img width="1988" alt="image" src="https://github.com/user-attachments/assets/b257d01e-3c16-4a38-b75e-413d0ce500f8">

    </div>
</article>

<div id="comments">
    <script src="https://utteranc.es/client.js" repo="geoqiao/geoqiao.github.io"
        issue-number="28" theme="github-light" crossorigin="anonymous" async>
        </script>
</div>

    </main>

    <footer>
        <div class="container">
            <p>&copy; 2024 GeoQiao's Blog</p>
        </div>
    </footer>

    <script src="https://geoqiao.github.io/templates/default_theme/static/js/prism.js"></script>
    <script src="https://geoqiao.github.io/templates/default_theme/static/js/main.js"></script>
</body>

</html>